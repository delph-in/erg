;;; -*- mode: fundamental; coding: iso-8859-1; indent-tabs-mode: t; -*-

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;; first shot at a finite-state language for preprocessing, normalization, and
;;; tokenization in LKB grammars.  requires LKB version after 1-feb-03.  note
;;; that the syntax is rigid: everything starting in column 2 (i.e. right after
;;; the rule type marker) is used as the match pattern until the first `\t'
;;; (tabulator sign); one or more tabulator sign are considered the separator
;;; between the matching pattern and the replacement, but other whitespace will
;;; be considered part of the patterns.  empty lines or lines with a semicolon
;;; in column 1 (i.e. in place of the rule type marker, this is not Lisp) will
;;; be ignored.
;;;
;;; rules are applied in order and, in the case of substitution rules, each see
;;; the output of the previous iteration.  token-level augmentation rules (the
;;; `+' type, for now) are different in that they add an alternative for the 
;;; token but the original form remains in the input buffer for subsequent rule
;;; applications (i.e. the alternative is _not_ visible to further rules).
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

;;;
;;; preprocessor rules versioning; auto-maintained upon CVS check-in.
;;; 
@$Date$

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;; tokenization pattern: after normalization, the string will be broken up at
;;; each occurrence of this pattern; the pattern match itself is deleted.
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
:[ \t]+

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;; string rewrite rules: all matches, over the entire string, are replaced by
;;; the right-hand side; grouping (using `(' and `)') in the pattern) and group
;;; references (`\1' for the first group, et al.) carry over part of the match.
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

;;;
;;; pad the full string with trailing and leading whitespace; makes matches for
;;; word boundaries a little easier down the road.
;;;
!^(.+)$					 \1 

;;;
;;; separate hash sign from right-adjacent number(s)
;;;
!([#(])([0-9])				\1 \2

;;; Replace three dots with token 'threedots '
!([.])([.])([.])			 threedots 

;;;
;;; replace multiple punctuation marks with only the last one, followed by
;;; space
;;;
!([?!.])[?!.]+		 		\1 

;;;
;;; for now, separate all parentheses and quote marks with whitespace on either
;;; side from the preceding and following material; do this before stripping
;;; off other punctuation to treat |"(`foo' bar.)"| properly.
;;;
;;; _fix_me_
;;; this rule, come to think of it, would be a candidate to apply recursively
;;; until it no longer matched (the `>' group call directive, once it was
;;; implemented; see `src/main/preprocess.lsp').            (15-feb-03; oe)
;;;
;;;
;;; for examples like |included in the "Sunmøre Alps".|, we also need to strip
;;; off the trailing quotes marks, even though they are immediately followed by
;;; a non-whitespace character, albeit a clause-final punctuation.
;;; DPF - Added backslash in front of double-quote so PET can find it.
;;; DPF - Replaced that hack with another: using vertical bars || in place of "
;;; DPF - Replaced |~| with |twidl| so PET can manage it
;;; DPF - PET also seems unable to see |`| so replacing it with |'| even
;;; though this adds spurious ambiguity. Better than nothing.
;;;
!(["`'])([ .!?:,;])			 \1\2
! (["`'])				 \1 
!(["`'])([ .!?:,;])			 \1\2
! ([()])				 \1 
!([()])				 	  \1
!(["`'])([ .!?:,;])			 \1\2
! ([`'])				 \1 
! (["])					 || 
! ([~])					 twidl 
! ([`])					 ' 
;;;
;;; _fix_me_
;;; at least for hyphens and probably periods, we should introduce a notion of
;;; `bound' tokens, e.g. |^.| for a hyphen that was stripped off from one or
;;; more tokens: |US-led| --> |US| |^-| |led|.  this way, separating hyphens as
;;; individual tokens need not create ambiguity with the parenthetical hyphen,
;;; say.  for periods in abbreviations, the lexical entry would have |Dr| |^.|
;;; as its orthography, i.e. is a multi-word of sorts.
;;;

;;; Replace "--" with "__" to keep double-hyphen separate from single hyphen
!([-]){2}				 __ 

;;; Collapse triple-hyphen with double-hyphen (for now), and pad on both
;;; sides with whitespace
!([-]){3}				 __ 

;;;
;;; for now, separate all punctuation with whitespace on either side from the
;;; preceding and following word(s).
;;;
!([-.?!:;,#$%~]) 			 \1 
! ([-.?!:;,$%~])				 \1 

;;;
;;; add white space on either side of squished commas, hyphens, and colons
;;; except for numbers on both sides (but separate e.g. |2-day|)
;;; do the same for forward slash
;;;
!([a-zA-Z])([-,:/])([a-zA-Z])		\1 \2 \3
!([0-9])([-,:/])([a-zA-Z])		\1 \2 \3
!([a-zA-Z])([-,:/])([0-9])		\1 \2 \3

;;;
;;; apostrophes are a bit tricky: generally, we want to separate leading and 
;;; trailing single quotes from adjacent word material, so that they become a
;;; separate token (e.g. |abrams'| --> |abrams '|); the possesive |'s|, on the
;;; other hand, we want to separate but then consider a single token.
;;;
!' 					 ' 
!([^ ])'[sS] 				\1 's 


;;;
;;; contracted auxiliaries: separate contracted part from preceding word.
;;;
!([^ ])'ll 				\1 'll 
!([^ ])'d 				\1 'd 
!([^ ])'ve 				\1 've 
!([^ ])'m 				\1 'm 
!([^ ])'re 				\1 're 
!([^ ])'LL 				\1 'LL 
!([^ ])'D 				\1 'D 
!([^ ])'VE 				\1 'VE 
!([^ ])'M 				\1 'M 
!([^ ])'RE 				\1 'RE 

;;;
;;; for now, throw away punctuation (analogous to what the built-in tokenizers
;;; in the LKB and PET used to do).
;;;
;;;![.?!,] 				 
;;;! [,] 				 

;;;
;;; Experimental: mark capitalization with preceding special character |^|
;;; but right now only for single letters used as proper names.
;;;
;! ([A-Z])([a-z]*) 			 ^ \1\2 
! ([A-Z]) 				 _\1 
;;; And for now, put back capital I since it's so frequent as pronoun
!_I					I
;;; Also add special treatment for abbrev OR for Oregon (consider also IN)
!OR					_OR

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;; file inclusion: there is an ad hoc set of `spell correction' rules for the
;;; static ecommerce data sets which we want to keep in a separate file.
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
<ecommerce.fsr
<gcide.fsr

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;; while we are working on this against several grammar versions, keep rules
;;; for LOGON hiking data in a file of their own.
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
<rondane.fsr

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;; from here on, token-specific rules, i.e. the pattern has to match the full
;;; string of the token (implicit `^' and `$' anchoring).  three types of rules
;;; for now: (i) substitution (`-'), replacing the token with the right-hand
;;; side match, (ii) augmentation (`+'), adding an alternative spelling for the
;;; token, and ersatzing (`^'), effectively a substitution but recording what
;;; the original string was for later retrieval (to be implementend :-).
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

;;;
;;; another type of token-level substitution rules: replace the token surface
;;; form with the replacement string (the `ersatz') but keep the original for
;;; later retrieval.
;;;

^[0-9]{1,2}[/-][0-9]{1,2}[/-][0-9]{4}		DateErsatz
^[0-9]{1,2}[/-][0-9]{1,2}[/-][0-9]{2}		DateErsatz
^[0-9]{1,2}[/-][0-9]{4}				DateErsatz
^[0-9]{1,2}[/-][0-9]{2}				DateErsatz

;;;
;;; phone numbers; making these a little more general would require more work.
;;;
^[0-9]{3}[-][0-9]{4}				3-4NumberErsatz

;;;
;;; product number identifiers like 1234-5678
;;;
^[0-9]{3,}[-][0-9]{3,}				NumberErsatz

^[0-9]{1,2}[-][0-9]{1,2}			RangeErsatz

;;;
;;; mixed alphanumerics as identifiers; for the ecommerce corpus, we know that
;;; (by convention) five- and six-digit sequences are (product) identifiers.
;;;
^[0-9]*[A-Z]+[0-9][A-Z0-9]*			IdentifierErsatz
^[0-9]+[A-Z]+[A-Z0-9]*				IdentifierErsatz
;^[0-9]{5}					IdentifierErsatz
;^[0-9]{6}					IdentifierErsatz

;;;
;;; _fix_me_
;;; in the case of hyphens, if we have decided to strip these off in the string
;;; rewrite rules already, the ersatzing at this point may fail.  it seems one
;;; would either have to allow ersatzing at the string level too and devise an
;;; encoding scheme (using 0x1 to 0x4, say, to number ersatz occurences) that
;;; makes sure ersatzes are not mangled in further string-level processing; at
;;; the end of the day, then, look up the original surface string and put the
;;; readable ersatz into the token.                           (2-feb-02; oe)
;;;
^[-a-zA-Z0-9]+@[-.a-zA-z0-9]+			EmailErsatz

;;;
;;; _fix_me_
;;; our numbers will need a little more work sometime.        (22-feb-03; oe)
;;;

;;; Fractions

^[0-9]{1}\/[0-9]{1,2}st				FractionErsatz
^[0-9]{1}\/[0-9]{1,2}nd				FractionErsatz
^[0-9]{1}\/[0-9]{1,2}rd				FractionErsatz
^[0-9]{1}\/[0-9]{1,2}th				FractionErsatz
^[0-9]{1}\/[0-9]{1,2}				FractionErsatz
^[0-9]{1,3},[0-9]{3}				NumberErsatz
^[0-9]{1,3},[0-9]{1,3},[0-9]{3}			NumberErsatz

;;; Cardinal numerals

^~?[2-9]{1}					OneDigitErsatz
^~?[0-9]{2}					TwoDigitErsatz
^~?[0-9]{3}					ThreeDigitErsatz
^~?[0-9]{4}					FourDigitErsatz
^~?[0-9]{5}					FiveDigitErsatz
^~?[0-9]{6}					SixDigitErsatz
^~?[0-9]{7}					SevenDigitErsatz
^~?[0-9]{8}					EightDigitErsatz
^~?[0-9]{9}					NineDigitErsatz
^~?[0-9]{10}					TenDigitErsatz
^~?[0-9]{11}					ElevenDigitErsatz
^~?[0-9]{12}					TwelveDigitErsatz
^~?[0-9]{13,}					ThirteenPlusDigitErsatz

;;; Numerical ordinals like "360th"

^1st						Onedigitordersatz
^[0-9]1st					Twodigitordersatz
^[0-9]{2}1st					Threedigitordersatz
^[0-9]{3}1st					Fourdigitordersatz
^2nd						Onedigitordersatz
^[0-9]2nd					Twodigitordersatz
^[0-9]{2}2nd					Threedigitordersatz
^[0-9]{3}2nd					Fourdigitordersatz
^3rd						Onedigitordersatz
^[0-9]3rd					Twodigitordersatz
^[0-9]{2}3rd					Threedigitordersatz
^[0-9]{3}3rd					Fourdigitordersatz
^[0-9]th					Onedigitordersatz
^[0-9]{2}th					Twodigitordersatz
^[0-9]{3}th					Threedigitordersatz
^[0-9]{4}th					Fourdigitordersatz

;;;
;;; a couple of currencies, as they occur now and again
;;;
^US\$						CurrencyErsatz
^HK\$						CurrencyErsatz
^C\$						CurrencyErsatz

;;;
;;; times
;;;
^[0-2]?[0-9]:[0-5][0-9]				ClockTimeErsatz
^[0-2]?[0-9]:[0-5][0-9][aA][mM]			ClockTimeErsatz
^[0-2]?[0-9]:[0-5][0-9][pP][mM]			ClockTimeErsatz
^[0-2]?[0-9].[0-5][0-9][aA][mM]			ClockTimeErsatz
^[0-2]?[0-9].[0-5][0-9][pP][mM]			ClockTimeErsatz
^[0-2]?[0-9][0-5][0-9][aA][mM]			ClockTimeErsatz
^[0-2]?[0-9][0-5][0-9][pP][mM]			ClockTimeErsatz
^[0-2]?[0-9].[0-5][0-9]				ClockorDecimalErsatz

; Move general decimal conversion to be after clocktime

^[0-9]+\.[0-9]+					DecimalErsatz
; Allow variant in some other countries, where comma rather than period is used
^[0-9]+\,[0-9]+					DecimalErsatz

;;;
;;; email and web addresses ... lots of room for improvement   (2-jul-03; oe)
;;;
^<?http://.*>?					WebErsatz
^<?www\.[a-zA-Z0-9.?%/_-]+>?			WebErsatz
^<?[a-zA-Z]{2,}\.[a-zA-Z]{2,}>?			WebErsatz
^<?[a-zA-Z]{2,}\.[a-zA-Z]{2,}\.[a-zA-Z]{2,}>?		WebErsatz
^<?[a-zA-Z0-9_-]{2,}@[a-zA-Z0-9._-]{2,}>?		EmailErsatz

;;;
;;; For the rest, add white space on either side of squished periods
;;; as in "Rte.66"
;;;

!([a-zA-Z])([-,:])([a-zA-Z])		\1 \2 \3
!([0-9])([-,:])([a-zA-Z])		\1 \2 \3
!([a-zA-Z])([-,:])([0-9])		\1 \2 \3


;;;
;;; reduced year names; possibly another case where, in full generality, we
;;; would have to be able to strip of the leading apostrophe first and later, 
;;; in the token-level part, introduce a tokenization alternative, re-uniting
;;; the apostrophe and two-digit year.
;;;
^'[0-9][0-9]					YearErsatz

;;;
;;; in the |1970s|, at least, the world was still in order ...
;;;
^1[0-9][0-9]0[sS]				DecadeErsatz
^[0-9]0[sS]					DecadeErsatz

;;; |an 800m hill|
;;;
^~?[0-9]+[m]					MeasNPErsatz
^~?[0-9]+[k][m]					MeasNPErsatz
^~?[0-9]+[.,-][0-9]+[m]				MeasNPErsatz
^~?[0-9]+[.,-][0-9]+[k][m]			MeasNPErsatz
