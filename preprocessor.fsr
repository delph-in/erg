;;; -*- mode: fundamental; coding: iso-8859-1; indent-tabs-mode: t; -*-

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;; first shot at a finite-state language for preprocessing, normalization, and
;;; tokenization in LKB grammars.  requires LKB version after 1-feb-03.  note
;;; that the syntax is rigid: everything starting in column 2 (i.e. right after
;;; the rule type marker) is used as the match pattern until the first `\t'
;;; (tabulator sign); one or more tabulator sign are considered the separator
;;; between the matching pattern and the replacement, but other whitespace will
;;; be considered part of the patterns.  empty lines or lines with a semicolon
;;; in column 1 (i.e. in place of the rule type marker, this is not Lisp) will
;;; be ignored.
;;;
;;; rules are applied in order and, in the case of substitution rules, each see
;;; the output of the previous iteration.  token-level augmentation rules (the
;;; `+' type, for now) are different in that they add an alternative for the 
;;; token but the original form remains in the input buffer for subsequent rule
;;; applications (i.e. the alternative is _not_ visible to further rules).
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

;;;
;;; preprocessor rules versioning; auto-maintained upon CVS check-in.
;;; 
@$Date$

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;; tokenization pattern: after normalization, the string will be broken up at
;;; each occurrence of this pattern; the pattern match itself is deleted.
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
:[ \t]+

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;; string rewrite rules: all matches, over the entire string, are replaced by
;;; the right-hand side; grouping (using `(' and `)') in the pattern) and group
;;; references (`\1' for the first group, et al.) carry over part of the match.
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

;;;
;;; pad the full string with trailing and leading whitespace; makes matches for
;;; word boundaries a little easier down the road.
;;;
!^(.+)$					 \1 

;;;
;;; separate hash sign from right-adjacent number(s)
;;;
!([#(])([0-9])				\1 \2

;;;
;;; replace multiple punctuation marks with only the last one, followed by
;;; space
;;;
!([?!.-])[?!.]+		 		\1 

;;;
;;; for now, separate all parentheses and quote marks with whitespace on either
;;; side from the preceding and following material; do this before stripping
;;; off other punctuation to treat |"(`foo' bar.)"| properly.
;;;
;;; _fix_me_
;;; this rule, come to think of it, would be a candidate to apply recursively
;;; until it no longer matched (the `>' group call directive, once it was
;;; implemented; see `src/main/preprocess.lsp').            (15-feb-03; oe)
;;;
;;;
;;; for examples like |included in the "Sunmøre Alps".|, we also need to strip
;;; off the trailing quotes marks, even though they are immediately followed by
;;; a non-whitespace character, albeit a clause-final punctuation.
;;; DPF - Added backslash in front of double-quote so PET can find it.
;;;
!(["`'])([ .!?:])			 \1\2
! (["`'])				 \1 
!(["`'])([ .!?:])			 \1\2
! ([()])				 \1 
!([()])				 	  \1
!(["`'])([ .!?:])			 \1\2
! ([`'])				 \1 
! (["])					 \\1 

;;;
;;; _fix_me_
;;; at least for hyphens and probably periods, we should introduce a notion of
;;; `bound' tokens, e.g. |^.| for a hyphen that was stripped off from one or
;;; more tokens: |US-led| --> |US| |^-| |led|.  this way, separating hyphens as
;;; individual tokens need not create ambiguity with the parenthetical hyphen,
;;; say.  for periods in abbreviations, the lexical entry would have |Dr| |^.|
;;; as its orthogphray, i.e. is a multi-word of sorts.
;;;

;;;
;;; for now, separate all punctuation with whitespace on either side from the
;;; preceding and following word(s).
;;;
!([-.?!:;,#$%]) 			 \1 
! ([-.?!:;,$%])				 \1 

;;;
;;; add white space on either side of squished commas, hyphens, and colons
;;; except for numbers on both sides (but separate e.g. |2-day|)
;;; FIX: This excludes an analysis of "please wait 7-10 days"
;;;
!([a-zA-Z])([-,:])([a-zA-Z])		\1 \2 \3
!([0-9])([-,:])([a-zA-Z])		\1 \2 \3
!([a-zA-Z])([-,:])([0-9])		\1 \2 \3

;;;
;;; do the same for forward slash if not numeric as in |dogs/cats|
;;;
!([a-zA-Z])(/)([a-zA-Z])		\1 \2 \3

;;;
;;; apostrophes are a bit tricky: generally, we want to separate leading and 
;;; trailing single quotes from adjacent word material, so that they become a
;;; separate token (e.g. |abrams'| --> |abrams '|); the possesive |'s|, on the
;;; other hand, we want to separate but then consider a single token.
;;;
!' 					 ' 
!([^ ])'[sS] 				\1 's 


;;;
;;; contracted auxiliaries: separate contracted part from preceding word.
;;;
!([^ ])'ll 				\1 'll 
!([^ ])'d 				\1 'd 
!([^ ])'ve 				\1 've 
!([^ ])'m 				\1 'm 
!([^ ])'re 				\1 're 
!([^ ])'LL 				\1 'LL 
!([^ ])'D 				\1 'D 
!([^ ])'VE 				\1 'VE 
!([^ ])'M 				\1 'M 
!([^ ])'RE 				\1 'RE 

;;;
;;; for now, throw away punctuation (analogous to what the built-in tokenizers
;;; in the LKB and PET used to do).
;;;
![.?!,] 				 
;;;! [,] 				 

;;;
;;; Experimental: mark capitalization with preceding special character |^|
;;;
;! ([A-Z])([a-z]*) 			 ^ \1\2 

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;; file inclusion: there is an ad hoc set of `spell correction' rules for the
;;; static ecommerce data sets which we want to keep in a separate file.
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
<ecommerce.fsr

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;; from here on, token-specific rules, i.e. the pattern has to match the full
;;; string of the token (implicit `^' and `$' anchoring).  three types of rules
;;; for now: (i) substitution (`-'), replacing the token with the right-hand
;;; side match, (ii) augmentation (`+'), adding an alternative spelling for the
;;; token, and ersatzing (`^'), effectively a substitution but recording what
;;; the original string was for later retrieval (to be implementend :-).
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

;;;
;;; another type of token-level substitution rules: replace the token surface
;;; form with the replacement string (the `ersatz') but keep the original for
;;; later retrieval.
;;;

^[0-9]{1,2}[/-][0-9]{1,2}[/-][0-9]{4}		DateErsatz
^[0-9]{1,2}[/-][0-9]{1,2}[/-][0-9]{2}		DateErsatz
^[0-9]{1,2}[/-][0-9]{4}				DateErsatz
^[0-9]{1,2}[/-][0-9]{2}				DateErsatz

;;;
;;; phone numbers; making these a little more general would require more work.
;;;
^[0-9]{3}[-][0-9]{4}				3-4NumberErsatz

;;;
;;; product number identifiers like 1234-5678
;;;
^[0-9]{3,}[-][0-9]{3,}				NumberErsatz

^[0-9]{1}[-][0-9]{1}				RangeErsatz

;;;
;;; mixed alphanumerics as identifiers; for the ecommerce corpus, we know that
;;; (by convention) five- and six-digit sequences are (product) identifiers.
;;;
^[0-9]*[A-Z]+[0-9][A-Z0-9]*			IdentifierErsatz
^[0-9]+[A-Z]+[A-Z0-9]*				IdentifierErsatz
^[0-9]{5}					IdentifierErsatz
^[0-9]{6}					IdentifierErsatz

;;;
;;; _fix_me_
;;; in the case of hyphens, if we have decided to strip these off in the string
;;; rewrite rules already, the ersatzing at this point may fail.  it seems one
;;; would either have to allow ersatzing at the string level too and devise an
;;; encoding scheme (using 0x1 to 0x4, say, to number ersatz occurences) that
;;; makes sure ersatzes are not mangled in further string-level processing; at
;;; the end of the day, then, look up the original surface string and put the
;;; readable ersatz into the token.                           (2-feb-02; oe)
;;;
^[-a-zA-Z0-9]+@[-.a-zA-z0-9]+			EmailErsatz

;;;
;;; _fix_me_
;;; our numbers will need a little more work sometime.        (22-feb-03; oe)
;;;
^[0-9]+\.[0-9]+					DecimalErsatz
^[0-9]{1,2}\\/[0-9]{1,2}			FractionErsatz
^[0-9]{1,3},[0-9]{3}				NumberErsatz
^[0-9]{1,3},[0-9]{1,3},[0-9]{3}			NumberErsatz

^[0-9]{1}					OneDigitErsatz
^[0-9]{2}					TwoDigitErsatz
^[0-9]{3}					ThreeDigitErsatz
^[0-9]{4}					FourDigitErsatz
^[0-9]{5}					FiveDigitErsatz
^[0-9]{6}					SixDigitErsatz
^[0-9]{7}					SevenDigitErsatz
^[0-9]{8}					EightDigitErsatz
^[0-9]{9}					NineDigitErsatz
^[0-9]{10}					TenDigitErsatz
^[0-9]{11}					ElevenDigitErsatz
^[0-9]{12}					TwelveDigitErsatz
^[0-9]{13,}					ThirteenPlusDigitErsatz

;;;
;;; a couple of currencies, as they occur now and again
;;;
^US\$						CurrencyErsatz
^HK\$						CurrencyErsatz
^C\$						CurrencyErsatz

;;;
;;; times
;;;
^[0-2]?[0-9]:[0-5][0-9]				ClockTimeErsatz

;;;
;;; email and web addresses ... lots of room for improvement   (2-jul-03; oe)
;;;
^<?http://.*>?					WebErsatz
^<?www\.[a-zA-Z0-9.?%/_-]+>?			WebErsatz
^<?[a-zA-Z0-9_-]+@[a-zA-Z0-9._-]+>?		EmailErsatz

;;;
;;; reduced year names; possibly another case where, in full generality, we
;;; would have to be able to strip of the leading apostrophe first and later, 
;;; in the token-level part, introduce a tokenization alternative, re-uniting
;;; the apostrophe and two-digit year.
;;;
^'[0-9][0-9]					YearErsatz

;;;
;;; in the |1970s|, at least, the world was still in order ...
;;;
^1[0-9][0-9]0[sS]				DecadeErsatz
^[0-9]0[sS]					DecadeErsatz

