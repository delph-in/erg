;;; -*- mode: fundamental; coding: iso-8859-1; indent-tabs-mode: t; -*-

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;; first shot at a finite-state language for preprocessing, normalization, and
;;; tokenization in LKB grammars.  requires LKB version after 1-feb-03.  note
;;; that the syntax is rigid: everything starting in column 2 (i.e. right after
;;; the rule type marker) is used as the match pattern until the first `\t'
;;; (tabulator sign); one or more tabulator sign are considered the separator
;;; between the matching pattern and the replacement, but other whitespace will
;;; be considered part of the patterns.  empty lines or lines with a semicolon
;;; in column 1 (i.e. in place of the rule type marker, this is not Lisp) will
;;; be ignored.
;;;
;;; rules are applied in order and, in the case of substitution rules, each see
;;; the output of the previous iteration.  token-level augmentation rules (the
;;; `+' type, for now) are different in that they add an alternative for the 
;;; token but the original form remains in the input buffer for subsequent rule
;;; applications (i.e. the alternative is _not_ visible to further rules).
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

;;;
;;; preprocessor rules versioning; auto-maintained upon CVS check-in.
;;; 
@$Date$

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;; tokenization pattern: after normalization, the string will be broken up at
;;; each occurrence of this pattern; the pattern match itself is deleted.
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
:[ \t]+

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;; string rewrite rules: all matches, over the entire string, are replaced by
;;; the right-hand side; grouping (using `(' and `)') in the pattern) and group
;;; references (`\1' for the first group, et al.) carry over part of the match.
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

;;;
;;; pad the full string with trailing and leading whitespace; makes matches for
;;; word boundaries a little easier down the road.
;;;
!^(.+)$					 \1 

;;;
;;; separate hash sign from right-adjacent number(s)
;;;
!([#(])([0-9])				\1 \2

;;;
;;; replace multiple punctuation marks with only the last one, followed by
;;; space
;;;
!([?!.-])[?!.-]+		 		\1 

;;;
;;; for now, separate all parentheses and quote marks with whitespace on either
;;; side from the preceding and following material; do this before stripping
;;; off other punctuation to treat |"(`foo' bar.)"| properly.
;;;
;;; _fix_me_
;;; this rule, come to think of it, would be a candidate to apply recursively
;;; until it no longer matched (the `>' group call directive, once it was
;;; implemented; see `src/main/preprocess.lsp').            (15-feb-03; oe)
;;;
!(["`']) 				 \1 
! (["`'])				 \1 
!([()])					 \1 
! ([()])				 \1 
!(["`']) 				 \1 
! (["`'])				 \1 

;;;
;;; _fix_me_
;;; at least for hyphens and probably periods, we should introduce a notion of
;;; `bound' tokens, e.g. |^.| for a hyphen that was stripped off from one or
;;; more tokens: |US-led| --> |US| |^-| |led|.  this way, separating hyphens as
;;; individual tokens need not create ambiguity with the parenthetical hyphen,
;;; say.  for periods in abbreviations, the lexical entry would have |Dr.| |^.|
;;; as its orthogphray, i.e. is a multi-word of sorts.
;;;

;;;
;;; for now, separate all punctuation with whitespace on either side from the
;;; preceding and following word(s).
;;;
!([-.?!:;,#]) 				 \1 
! ([-.?!:;,])				 \1 

;;;
;;; add white space on either side of squished commas, hyphens, and colons
;;; except for numbers on both sides (but separate e.g. "2-day")
;;;
!([a-zA-Z])([-,:])([a-zA-Z])		\1 \2 \3
!([0-9])([-,:])([a-zA-Z])		\1 \2 \3
!([a-zA-Z])([-,:])([0-9])		\1 \2 \3

;;;
;;; do the same for forward slash if not numeric as in |dogs/cats|
;;;
!([a-zA-Z])(/)([a-zA-Z])		\1 \2 \3

;;;
;;; apostrophes are a bit tricky: generally, we want to separate leading and 
;;; trailing single quotes from adjacent word material, so that they become a
;;; separate token (e.g. |abrams'| --> |abrams '|); the possesive |'s|, on the
;;; other hand, we want to separate but then consider a single token.
;;;
!' 					 ' 
!([^ ])'[sS] 				\1 's 


;;;
;;; contracted auxiliaries: separate contracted part from preceding word.
;;;
!([^ ])'ll 				\1 'll 
!([^ ])'d 				\1 'd 
!([^ ])'ve 				\1 've 
!([^ ])'m 				\1 'm 
!([^ ])'re 				\1 're 
!([^ ])'LL 				\1 'LL 
!([^ ])'D 				\1 'D 
!([^ ])'VE 				\1 'VE 
!([^ ])'M 				\1 'M 
!([^ ])'RE 				\1 'RE 

;;;
;;; for now, throw away punctuation (analogous to what the built-in tokenizers
;;; in the LKB and PET used to do).
;;;
! [,()`] 				 

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;; from here on, token-specific rules, i.e. the pattern has to match the full
;;; string of the token (implicit `^' and `$' anchoring).  three types of rules
;;; for now: (i) substitution (`-'), replacing the token with the right-hand
;;; side match, (ii) augmentation (`+'), adding an alternative spelling for the
;;; token, and ersatzing (`^'), effectively a substitution but recording what
;;; the original string was for later retrieval (to be implementend :-).
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

;;;
;;; lacking a proper spell corrector, we do what needs to be done for the EC
;;; corpus in the preprocessing rules; this is entirely ad hoc.
;;;
-recieve				receive
-recieves				receives
-recieved				received
-recieving				receiving
-recived				received
-reeived				received
-receieved				received
-orderd					ordered
-ordereed				ordered
-recweipt				receipt
-goin					going
-oing					going
-goint					going
-wht					what
-cutomers				customers
-nrmally				normally
-orderc					orders
-happend				happened
-happned				happened
-hoiw					how
-ordrer					order
-teh					the
-didn;t					didn't
-have't					haven't
-everyting				everything
-inqueries				inquiries
-awsome					awesome
-undersrtand				understand
!eventhough				even though
!suppoesedto				supposed to
!-wha't					what 's
-whethere				whether
-has't					hasn't
-acceped				accepted
-corrctly				correctly
-appriciated				appreciated
-inconvinience				inconvenience
-degital				digital
-[Pp]laese				please
-[Pp]leasae				please
-vacatation				vacation
-detexctor				detector
-[Hh]epl				help
-[Aa]drres				address
-tks					thanks
-trackionn				tracking
-dlay					delay
-expcet					expect
-sometning				something
-thorugh				through
-cna					can
-waitin					waiting
-lapto					laptop
-loptap					laptop
-nubmer					number
-numer					number
-agao					ago
-orde					order
-oder					order
-mey					my
-knhow					know
-[Vv]io					vaio
-tring					trying
-ericcson				ericson
-[Ee]rickson				ericson
-delyaed				delayed
-arived					arrived
-hans't					hasn't
-worng					wrong
-ther					there
-USPC					USPS
-IMB					IBM
-22th					22nd

+fo					of
+stats					status
+youn					you
+th					the
+you					your
+form					from
+b4					before
+expectd				expect

;;;
;;; another type of token-level substitution rules: replace the token surface
;;; form with the replacement string (the `ersatz') but keep the original for
;;; later retrieval.
;;;

^[0-9]{1,2}[/-][0-9]{1,2}[/-][0-9]{4}		DateErsatz
^[0-9]{1,2}[/-][0-9]{1,2}[/-][0-9]{2}		DateErsatz
^[0-9]{1,2}[/-][0-9]{4}				DateErsatz
^[0-9]{1,2}[/-][0-9]{2}				DateErsatz

;;; Phone numbers
^[0-9]{3}[-][0-9]{4}				3-4NumberErsatz

;;; Product number identifiers like 1234-5678
^[0-9]{3,}[-][0-9]{3,}				NumberErsatz

^[0-9]{1}[-][0-9]{1}				RangeErsatz

;;; Mixed alphanumerics as identifiers
^[0-9]*[A-Z]+[0-9][A-Z0-9]*		IdentifierErsatz
^[0-9]+[A-Z]+[A-Z0-9]*			IdentifierErsatz

;;;
;;; _fix_me_
;;; in the case of hyphens, if we have decided to strip these off in the string
;;; rewrite rules already, the ersatzing at this point may fail.  it seems one
;;; would either have to allow ersatzing at the string level too and devise an
;;; encoding scheme (using 0x1 to 0x4, say, to number ersatz occurences) that
;;; makes sure ersatzes are not mangled in further string-level processing; at
;;; the end of the day, then, look up the original surface string and put the
;;; readable ersatz into the token.                           (2-feb-02; oe)
;;;
^[-a-zA-Z0-9]+@[-.a-zA-z0-9]+		EmailErsatz

;;;
;;; _fix_me_
;;; our numbers will need a little more work sometime.        (22-feb-03; oe)
;;;
^[0-9]+\.[0-9]+				DecimalErsatz
^[0-9]{1,2}\\/[0-9]{1,2}		FractionErsatz
^[0-9]{1,3},[0-9]{3}			NumberErsatz
^[0-9]{1,3},[0-9]{1,3},[0-9]{3}		NumberErsatz

^[0-9]{1}				OneDigitErsatz
^[0-9]{2}				TwoDigitErsatz
^[0-9]{3}				ThreeDigitErsatz
^[0-9]{4}				FourDigitErsatz
^[0-9]{5}				FiveDigitErsatz
^[0-9]{6}				SixDigitErsatz
^[0-9]{7}				SevenDigitErsatz
^[0-9]{8}				EightDigitErsatz
^[0-9]{9}				NineDigitErsatz
^[0-9]{10}				TenDigitErsatz
^[0-9]{11}				ElevenDigitErsatz
^[0-9]{12}				TwelveDigitErsatz
^[0-9]{13,}				ThirteenPlusDigitErsatz

;;;
;;; a couple of currencies, as they occur now and again
;;;
^US\$					CurrencyErsatz
^HK\$					CurrencyErsatz

;;;
;;; times
;;;
^[0-2]?[0-9]:[0-5][0-9]			ClockTimeErsatz

;;;
;;; reduced year names; possibly another case where, in full generality, we
;;; would have to be able to strip of the leading apostrophe first and later, 
;;; in the token-level part, introduce a tokenization alternative, re-uniting
;;; the apostrophe and two-digit year.
;;;
^'[0-9][0-9]				YearErsatz
