;;; -*- Mode: tdl; Coding: utf-8; -*-

;;;
;;; token mapping is the process of inspecting and re-arranging input tokens,
;;; i.e. a lattice of structured objects (feature structures), to best match
;;; the expectations of the grammar proper.  the general mechnism is described
;;; by Adolphs, et al. (2008); see:
;;;
;;;   http://www.lrec-conf.org/proceedings/lrec2008/summaries/349.html
;;;
;;; as of August 2008, we are assuming an initial tokenization that is (mostly)
;;; compatible to Penn Treebank (PTB) conventions; this may or may not turn out
;;; to be a good idea, but if nothing else it makes the core parser compatible
;;; with a wide variety of existing tools and pre-processing approaches.  for a
;;; critical (and subjective) discussion of some tokenization issues, see:
;;;
;;;  http://lingpipe-blog.com/2008/06/26/the-curse-of-intelligent-tokenization/
;;;
;;; in the process of token mapping, we move from a PTB-compatible tokenization
;;; to an ERG-compatible one: specifically, many punctuation marks are attached
;;; as prefixes or suffixes on other tokens.  the process is broken down into a
;;; number of (more or less) distinct phases, viz.
;;;
;;; - normalization: anything the (ideal) tokenizer _should_ have done.
;;; - NE recognition: surface-based identification of URLs, numbers, et al.
;;; - decoration: filling in missing or underspecified token properties.
;;; - token combination: re-attach punctuation marks and contracted forms.
;;; - sandwiched punctuation
;;; - PoS explosion: multiply out alternate PoS readings
;;; - PoS reduction: prune overlapping PoS readings
;;;
;;; we hope we have (now) arrived at a relatively stable inventory of token
;;; properties, of which some typically are only introduced in token mapping;
;;; these are ONSET, PRED, CARG.  however, in principle a tokenizer might pass
;;; in any of these properties, or they could be introduced very early in the
;;; rewrite process.  hence, all rules must make sure to always preserve all
;;; token information.
;;;

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;
;;; correct tokenization `damage', inherited from the PTB conventions.
;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

;;
;; convert (PTB-style) ASCII directional quotes to UniCode characters.  when
;; running from an actual PTB file, these are what we would see as input.
;;
opening_double_quote := one_one_form_tmt &
[ +INPUT < [ +FORM "``" ] >,
  +OUTPUT < [ +FORM "“" ] > ].
           
closing_double_quote := one_one_form_tmt &
[ +INPUT < [ +FORM "''" ] >,
  +OUTPUT < [ +FORM "”" ] > ].
           

;;
;; {|do| |has| |wo| ...} |n't| --> {|don't| |hasn't| |won't| 
;;
contracted_negation_tmr := token_mapping_rule &
[ +INPUT < [ +FORM "/([[:alpha:]]+)/", 
             +ONSET #onset, +CLASS #class, +PRED #pred, +CARG #carg, 
             +FROM #from, +TNT #tnt ],
           [ +FORM "/(n't|N'T)/",
             +TO #to ] >,
  +OUTPUT < [ +FORM "${I1:+FORM:1}${I2:+FORM:1}",
              +ONSET #onset, +CLASS #class, +PRED #pred, +CARG #carg, 
              +FROM #from, +TO #to, +TNT #tnt ] >,
  +POSITION "I1<I2" ].



;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;
;;; lightweight NEs: form-driven generic entries (formerly `ersatz' entries)
;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

;;;
;;; email addresses
;;;

;;
;; any valid DNS string, prefixed by address, with optional angle brackets
;;
email_ne_tmr := ne_tmt &
[ +INPUT < [ +FORM
             "/<?[[:alnum:]._-]+@[[:alnum:]_-]+(\\.[[:alnum:]_-]+)+>?/" ] >,
  +OUTPUT < [ +CLASS email_ne ] > ].

;;;
;;; uniform resource locators (URLs)
;;;

;;
;; any valid DNS string, prefixed by `http://', with optional angle brackets
;;
url_ne_1_tmr := ne_tmt &
[ +INPUT < [ +FORM "/<?http://[[:alnum:]_-]+(\\.[[:alnum:]_-]+)+>?/" ] >,
  +OUTPUT < [ +CLASS url_ne ] > ].

;;
;; any valid DNS string, prefixed by `www', with optional angle brackets
;;
url_ne_2_tmr := ne_tmt &
[ +INPUT < [ +FORM "/<?www(\\.[[:alnum:]_-]+)+>?/" ] >,
  +OUTPUT < [ +CLASS url_ne ] > ].

;;
;; any valid DNS string, with obligatory angle brackets
;;
url_ne_3_tmr := ne_tmt &
[ +INPUT < [ +FORM "/<[[:alnum:]_-]+(\\.[[:alnum:]_-]+)+>/" ] >,
  +OUTPUT < [ +CLASS url_ne ] > ].

;;;
;;; file names
;;;

;;
;; fully-qualified Un*x style, starting with a slash, e.g. |/etc/config|.  
;;
;; _fix_me_
;; we require a minimum of two components, such that |/etc| by itself will not
;; match.  maybe we should allow these too but create an ambiguity here, i.e.
;; output two tokens, one [ CLASS file_ne }, the other [ CLASS non_ne ]?
;;                                                              (19-sep-08; oe)
;;
file_ne_tmr := ne_tmt &
[ +INPUT < [ +FORM "/(/[[:alnum:]._-]+){2,}/?/" ] >,
  +OUTPUT < [ +CLASS file_ne ] > ].


;;;
;;; time-of-day expressions: |9am|, |11:45pm|, |20:15|
;;;

;;
;; an |am| or |pm| suffix unambiguously indicates a time expression.  we also
;; grab all tokens of the form `H:M' where `H' and `M' are numbers in the right
;; ranges.
;;
;; _fix_me_
;; i wonder about `mix in a ratio of 1:15', which the second rule below would
;; consider a time-of-day expression.  should we approach those case with more
;; `optional' NE rules, i.e. ones outputting two tokens?  or should we rather
;; introduce an abstraction over `time_ne' and `ratio_ne', such that a single
;; token can activate multiple lexical entries?  once we get regular expression
;; matching for lexical instantiation (peter is working on that), in principle,
;; we could just drop `time_ne_2_tmr', make `time_ne_ a sub-type of `ratio_ne',
;; and put the `H:M' regular expression into the generic lexical entry.  with
;; great power comes great responsibility :-).                 (19-sep-08; oe)
;;                       
time_ne_1_tmr := ne_tmt &
[ +INPUT < [ +FORM "/(0?[0-9]|1[0-2])(:[0-5][0-9])?([aApP][mM])/" ] >,
  +OUTPUT  < [ +CLASS time_ne ] > ].

time_ne_2_tmr := ne_tmt &
[ +INPUT < [ +FORM "/(0?[0-9]|1[0-9]|2[0-4]):[0-5][0-9]/" ] >,
  +OUTPUT  < [ +CLASS time_ne ] > ].

;;;
;;; ratios: |1:1000|, |1:100,000|, et al.
;;;

;;
;; we make the conservative assumption that the first element not exceed three
;; digits and not have leading zeros.
;;
ratio_ne_1_tmr := ne_tmt &
[ +INPUT < [ +FORM "/[1-9][0-9]{0,2}:[1-9][0-9]*/" ] >,
  +OUTPUT < [ +CLASS meas_ne ] > ].   

ratio_ne_2_tmr := ne_tmt &
[ +INPUT < [ +FORM "/[1-9][0-9]{0,2}:[1-9][0-9]{2}(,[0-9]{1,3})*/" ] >,
  +OUTPUT < [ +CLASS meas_ne ] > ].   


;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;
;;; now with NEs out of our way, this would be a good time for adjustments to
;;; tokenization: introduce additional token boundaries (e.g. for hyphens and 
;;; slashes) and maybe some robustness rules for `sandwiched' punctuation.
;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;


;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;
;;; some tokenizers (e.g. the one of acrolinx) already distinguish a number of
;;; token classes.  our REPP tokenizer, however, does not; so, determine class
;;; values here, if need be.  with acrolinx, we might have to map their naming
;;; scheme into our type hierarchy, on the other hand.
;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

numeric_class_tmr := token_class_tmt &
[ +INPUT < [ +FORM "/[[:digit:]]+/" ] >,
  +OUTPUT < [ +CLASS numeric ] > ].

alphabetic_class_tmr := token_class_tmt &
[ +INPUT < [ +FORM "/[[:alpha:]]+/" ] >,
  +OUTPUT < [ +CLASS alphabetic ] > ].

alphanumeric_class_tmr := token_class_tmt &
[ +INPUT < [ +FORM "/[[:alnum:]_-]+/" ] >,
  +OUTPUT < [ +CLASS alphanumeric ] > ].

non_alphanumeric_class_tmr := token_class_tmt &
[ +OUTPUT < [ +CLASS non_alphanumeric ] > ].

;;
;; further decorate the token class with information about (a) sentence-initial
;; initial position and (b) capitalization.  because these are attributes of
;; +CLASS (and there is no way of overwriting), we play a nasty trick on +CARG,
;; viz. utilize it as a `scratch' slot to prevent cyclic rule applications.  we
;; (kind of assume) that no external tokenizer will pass in +CARG values, and
;; if it did, the worst that would happen is that the rules below cannot fire.
;;
non_initial_tmr := token_case_tmt &
[ +CONTEXT < [] >,
  +INPUT < [ +CARG anti_string ] >,
  +OUTPUT < [ +CLASS [ +INITIAL - ], +CARG non_string ] >,
  +POSITION "C1<I1" ].

initial_tmr := token_case_tmt &
[ +INPUT < [ +CARG anti_string ] >,
  +OUTPUT < [ +CLASS #class & [ +INITIAL + ], +CARG non_string ] > ].

lower_tmr := token_case_tmt &
[ +INPUT < [ +FORM "/[[:lower:][:digit:]_-]+/", 
             +CARG non_string ] >,
  +OUTPUT < [ +CLASS [ +CASE lower ], 
              +CARG anti_string ] > ].

upper_tmr := token_case_tmt &
[ +INPUT < [ +FORM "/[[:upper:][:digit:]_-]+/", 
             +CARG non_string ] >,
  +OUTPUT < [ +CLASS [ +CASE upper ], 
              +CARG anti_string ] > ].
  
capitalized_tmr := token_case_tmt &
[ +INPUT < [ +FORM "/[[:upper:]][[:alnum:]_-]+/", 
             +CARG non_string ] >,
  +OUTPUT < [ +CLASS [ +CASE capitalized+mixed ],
              +CARG anti_string ] > ].

non_capitalized_tmr := token_case_tmt &
[ +INPUT < [ +FORM "/[[:lower:][:digit:]][[:alnum:]_-]+/", 
             +CARG non_string ] >,
  +OUTPUT < [ +CLASS [ +CASE non_capitalized+mixed ],
              +CARG anti_string ] > ].

;;
;; in case we are running without a PoS tagger, or something went wrong in the
;; creation of token AVMs from our input (in one form or another), make sure to
;; fully annul part-of-speech information.
;;
null_tnt_tmr := token_mapping_rule &
[ +INPUT < [ +FORM #form, +ONSET #onset, +CLASS #class,
             +PRED #pred, +CARG #carg, +ID #id, +FROM #from, +TO #to,
             +TNT [ +TAGS < anti_string, ... > ] ] >,
  +OUTPUT < [ +FORM #form, +ONSET #onset, +CLASS #class,
              +PRED #pred, +CARG #carg, +ID #id, +FROM #from, +TO #to, 
              +TNT null_tnt ] > ].


;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;
;;; re-combine punctuation marks with adjacent tokens, based on directionality
;;; of punctuation marks, e.g. opening vs. closing quotes and brackets.  doing
;;; one such re-combination at a time is sufficient, as each rewrite rule will
;;; apply as many times as it possible can, seeing its own output from earlier
;;; applications.
;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

;;
;; but first, preserve the current (non-punctuated) from in +CARG, for later
;; reference, e.g. in constructing +PRED values for generics.  NE rules have
;; done this already, hence make sure to not overwrite existing +CARGSs.
;;
default_carg_tmr := token_mapping_rule &
[ +INPUT < [ +FORM #form, +ONSET #onset, +CLASS #class,
             +PRED #pred, +CARG anti_string,
             +ID #id, +FROM #from, +TO #to, +TNT #tnt ] >,
  +OUTPUT < [ +FORM #form, +ONSET #onset, +CLASS #class,
              +PRED #pred, +CARG #form,
              +ID #id, +FROM #from, +TO #to, +TNT #tnt ] > ].

prefix_punctuation_tmr := token_mapping_rule &
[ +INPUT < [ +FORM "/([[({“‘]+)/",
             +FROM #from ],
           [ +FORM "/(.+)/",
             +ONSET #onset, +CLASS #class, +PRED #pred, +CARG #carg, 
             +TO #to, +TNT #tnt ] >,
  +OUTPUT < [ +FORM "${I1:+FORM:1}${I2:+FORM:1}",
             +ONSET #onset, +CLASS #class, +PRED #pred, +CARG #carg, 
             +FROM #from, +TO #to, +TNT #tnt ] >,
  +POSITION "I1<I2" ].

;;
;; _fix_me_
;; there is a special case here: |'| following a token ending in |s| could be a
;; possessive marker (which should remain a token in its own right), or could 
;; be a closing single quote.  in principle, the same is true for |"|, but the
;; `feet' measure unit, possibly, will have been detected during NE recognition
;; earlier.  in either case, we would need a way of keeping a separate |'| in
;; the chart, and also re-combine it with the preceding token.  (14-sep-08; oe)
;;
suffix_punctuation_tmr := token_mapping_rule &
[ +INPUT < [ +FORM "/(.+)/",
             +ONSET #onset, +CLASS #class, +PRED #pred, +CARG #carg, 
             +FROM #from, +TNT #tnt ],
           [ +FORM "/([])}”\"’,;.!?]+)/",
             +TO #to ] >,
  +OUTPUT < [ +FORM "${I1:+FORM:1}${I2:+FORM:1}",
              +ONSET #onset, +CLASS #class, +PRED #pred, +CARG #carg, 
              +FROM #from, +TO #to, +TNT #tnt ] >,
  +POSITION "I1<I2" ].


;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;
;;; finally, convert everything to lower case, for lexical look-up in PET
;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

downcase_tmr := one_one_form_tmt &
[ +INPUT < [ +FORM "/(.*[[:upper:]].*)/",
             +ONSET #onset, +CLASS #class, +PRED #pred, +CARG #carg, 
             +ID #id, +FROM #from, +TO #to, +TNT #tnt ] > ,
  +OUTPUT < [ +FORM "${lc(I1:+FORM:1)}",
              +ONSET #onset, +CLASS #class, +PRED #pred, +CARG #carg, 
              +ID #id, +FROM #from, +TO #to, +TNT #tnt ] > ].


;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;
;;; at this point, we multiply out PoS values on all tokens, where for each
;;; original token as many additional tokens are created (in the same chart
;;; cell) as there are PoS readings.  at this point, we start distinguishing
;;; between tokens that activate native lexical entries (LEs), vs. those that
;;; activate generic LEs.  in the token universe, this distinction is made by
;;; virtue of +ONSET, with unk_onset reserved for generic LEs.  the two sets
;;; do not overlap, i.e. for a single original token with two PoS readings, we
;;; end up with a total of three new tokens.  the pair of rules below resembles
;;; a recursive function, terminating once the PoS list has been reduced to 
;;; a singleton element.  form-based named entities identified earlier avoid
;;; this kind of PoS multiplication because they have already emptied out their
;;; PoS list.
;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

tnt_recurse_rule := token_mapping_rule &
[ +INPUT < [ +FORM #form, +ONSET anti_onset,
             +CLASS #class, +PRED #pred, +CARG #carg,
             +ID #id, +FROM #from, +TO #to,
             +TNT [ +TAGS < #tag . #tags & *cons* >,
                    +PRBS < #prb . #prbs & *cons* > ] ] > ,
  +OUTPUT < [ +FORM #form, +ONSET unk_onset,
              +CLASS #class, +PRED #pred, +CARG #carg,
              +ID #id, +FROM #from, +TO #to,
              +TNT [ +TAGS < #tag >, +PRBS < #prb > ] ],
            [ +FORM #form,
              +CLASS #class, +PRED #pred, +CARG #carg,
              +ID #id, +FROM #from, +TO #to,
              +TNT [ +TAGS #tags, +PRBS #prbs ] ] > ,
  +POSITION "O1=O2" ].

tnt_terminate_tmr := token_mapping_rule &
[ +INPUT < [ +FORM #form, +ONSET anti_onset,
             +CLASS #class, +PRED #pred, +CARG #carg,
             +ID #id, +FROM #from, +TO #to,
             +TNT [ +TAGS < #tag >, +PRBS < #prb > ] ] > ,
  +OUTPUT < [ +FORM #form, +ONSET unk_onset,
              +CLASS #class, +PRED #pred, +CARG #carg,
              +ID #id, +FROM #from, +TO #to,
              +TNT [ +TAGS < #tag >, +PRBS < #prb > ] ],
            [ +FORM #form, +ONSET con_or_voc,
              +CLASS #class, +PRED #pred, +CARG #carg,
              +ID #id, +FROM #from, +TO #to,
              +TNT null_tnt ] >,
  +POSITION "O1=O2" ].

;;;
;;; with singleton PoS readings multiplied out in each chart cell, we can prune
;;; undesirable alternatives, e.g. a foreign word reading when there also is a
;;; common noun.  also, ditch PoS readings with very low probability, and ones
;;; for which no PoS-activated generic entries exist anyway.
;;;
;;; _fix_me_
;;; should we eventually want to include the PoS probabilities as a feature in
;;; parse selection, this kind of pruning should disappear: a high-probability
;;; FW, say, should not be bullied out by an unlike NN.         (31-aug-08; oe)
;;;

tnt_ditch_unlikely_tmr := token_mapping_rule &
[ +INPUT < [ +TNT.+PRBS < "/0?\\.0.*/" > ] >,
  +OUTPUT < > ].

tnt_ditch_function_tmr := token_mapping_rule &
[ +INPUT < [ +TNT.+TAGS 
             < "/CC|DT|EX|IN|MD|PDT|POS|PRP\\$?|RP|TO|UH|WDT|WP|WRB/" > ] >,
  +OUTPUT < > ].

tnt_ditch_punctuation_tmr := token_mapping_rule &
[ +INPUT < [ +TNT.+TAGS < "/\\$|#|``|''|\\(|\\)|,|\\.|:/" > ] >,
  +OUTPUT < > ].

tnt_filter_dup_fw_tmr := token_mapping_rule &
[ +CONTEXT  < [ +TNT.+TAGS < "NN" > ] >,
  +INPUT    < [ +TNT.+TAGS < "FW" > ] >,
  +OUTPUT   < >,
  +POSITION "I1=C1" ].

tnt_filter_dup_nnp_tmr := token_mapping_rule &
[ +CONTEXT  < [ +TNT.+TAGS < "/FW|NN/" > ] >,
  +INPUT    < [ +TNT.+TAGS < "NNP" > ] >,
  +OUTPUT   < >,
  +POSITION "I1=C1" ].

tnt_filter_dup_nnps_tmr := token_mapping_rule &
[ +CONTEXT  < [ +TNT.+TAGS < "NNP" > ] >,
  +INPUT    < [ +TNT.+TAGS < "NNPS" > ] >,
  +OUTPUT   < >,
  +POSITION "I1=C1" ].

#|
;;
;; _fix_me_
;; the following seems to not work, in that ${lc(I1:+TNT.+TAGS.+FIRST:1)} ends
;; up as a literal in the result; ditching the `lc(...) makes no difference
;; either, so i suspect there may be a bug related to the `+TNT.+TAGS.+FIRST'
;; path.  check with peter.                                    (19-sep-08; oe)
;;
generic_pred_tmr := token_mapping_rule &  
[ +INPUT < [ +FORM #form & "/(.+)/",
             +ONSET #onset & unk_onset, +CLASS #class & non_ne, 
             +PRED anti_string, +CARG #carg,
             +ID #id, +FROM #from, +TO #to,
             +TNT #tnt & [ +TAGS < "/(.+)/" > ] ] >,
  +OUTPUT < [ +FORM #form,
              +ONSET #onset, +CLASS #class,
              +PRED "_${I1:+FORM:1}_${lc(I1:+TNT.+TAGS.+FIRST:1)}_rel",
              +CARG #carg,
              +ID #id, +FROM #from, +TO #to,
              +TNT #tnt ] > ].
|#

generic_pred_nn_tmr := token_mapping_rule &  
[ +INPUT < [ +FORM #form,
             +ONSET #onset & unk_onset, +CLASS #class & non_ne, 
             +PRED anti_string, +CARG #carg & "/(.+)/",
             +ID #id, +FROM #from, +TO #to,
             +TNT #tnt & [ +TAGS < "/NNS?/" > ] ] >,
  +OUTPUT < [ +FORM #form,
              +ONSET #onset, +CLASS #class, 
              +PRED "_${I1:+CARG:1}_n_rel", +CARG #carg,
              +ID #id, +FROM #from, +TO #to, +TNT #tnt ] > ].

#|
generic_pred_nn_tmr := token_mapping_rule &  
[ +INPUT < [ +FORM #form,
             +ONSET #onset & unk_onset, +CLASS #class & non_ne, 
             +PRED anti_string, +CARG #carg,
             +ID #id, +FROM #from, +TO #to,
             +TNT #tnt & [ +TAGS < "/NNS?/" > ] ] >,
  +OUTPUT < [ +FORM #form,
              +ONSET #onset, +CLASS #class, 
              +PRED "foobar_n_rel", +CARG #carg,
              +ID #id, +FROM #from, +TO #to, +TNT #tnt ] > ].
|#

