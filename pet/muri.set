include "common".
include "mrs".

;start-symbols := $root_strict.
;start-symbols := $root_strict $root_informal.
start-symbols := $root_strict $root_frag $root_informal $root_inffrag.
;start-symbols := $root_strict $root_frag $root_informal $root_inffrag $root_robust.
;start-symbols := $root_strict $root_frag.
;start-symbols := $root_strict $root_informal $root_robust.

;punctuation-characters := "<>{}+*`".
punctuation-characters := "".
case-sensitive.               ; be case sensitive in string and YY tokenizer
;trivial-tokenizer.            ; for LinGO-style tokenizer ``string''

;;;
;;; the following two turn on (procedural) `characterization', i.e. code that
;;; will destructively modify the AVMs of new edges, to record the surface
;;; positions (as passed in from an expernal tokenizer) in each new relation.
;;; i.e. those that have no characterization information yet.  this mechanism
;;; is brittle (both in the LKB and PET), and we hope to eventually replace it
;;; in the new chart mapping universe: there, the grammarian get full control
;;; over how to `pick up' information from input tokens, and characterization
;;; can be accomplished without a specialized procedure `behind the scenes'.
;;;
mrs-cfrom-path := "SYNSEM.LOCAL.CONT.RELS.LIST.CFROM".
mrs-cto-path   := "SYNSEM.LOCAL.CONT.RELS.LIST.CTO".

;;;
;;; following are a number of settings for the new (as of late 2008) token
;;; mapping and lexical filtering support in PET.
;;;

;;;
;;; first, the general format of chart mapping rules, much like MRS transfer.
;;;
chart-mapping-context-path  := "+CONTEXT".
chart-mapping-input-path    := "+INPUT".
chart-mapping-output-path   := "+OUTPUT".
chart-mapping-position-path := "+POSITION".
;;;
;;; in lexical instatiation, the list of tokens activating a lexical entry (be
;;; it native or generic) are unified into the lexical entry under this path.
;;;
lexicon-tokens-path := "TOKENS.+LIST".
lexicon-last-token-path := "TOKENS.+LAST".
;;;
;;; furthermore, for the various input formats, we need to declare how parts of
;;; input descriptions correspond to the grammar-internal feature geometry; in
;;; the YY input format, for example, token feature structures (aka input items
;;; PET-internally) are created from various parts of the token description.
;;; 
token-form-path     := "+FORM".       ; [required] string for lexical lookup
;token-id-path       := "+ID".         ; [optional] list of external ids
token-from-path     := "+FROM".       ; [optional] surface start position
token-to-path       := "+TO".         ; [optional] surface end position
token-postags-path  := "+TNT.+TAGS".  ; [optional] list of POS tags
token-posprobs-path := "+TNT.+PRBS".  ; [optional] list of POS probabilities
