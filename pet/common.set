;;; -*- Mode: tdl; Coding: utf-8; indent-tabs-mode: nil; -*-

;;;
;;; this file is part of the ERG.  it should be kept in the same directory as 
;;; the accompanying files `english.set', `global.set', etc.
;;;

encoding := utf-8.

include "global".

;;
;; suppress results of regular morphology rules if irregular form exists
;;
irregular-forms-only.

lex-entries-can-fail.

;;
;; activate `lexical parsing' as a separate phase, i.e. invoke lexical rules
;; until a fixpoint is reached (see comments in `lfr.tdl' for background).
;;
lex-exhaustive.

;;
;; names of attributes not to pass from daughter to mother in parsing
;;
deleted-daughters := 
  ARGS HD-DTR NH-DTR LCONJ-DTR RCONJ-DTR DTR1 DTR2 DTRA DTRB DTR.

;;
;; names of attributes to filter for packing parser
;;
packing-restrictor := RELS HCONS RNAME.

;;
;; name of type containing quick check structure
;;
qc-structure := $qc_paths_set.

;;
;; based on selectional dependencies between lexical entries, reduce the chart
;; right after lexical look-up: `chart-dependencies' is a list of pairs of
;; paths into lexical entries.  the type of the node at the end of the first
;; path in one lexical entry makes that entry depend on the existence of some
;; other lexical entry that has that same type as the value of the node at the
;; end of the second path.
;;
;; _fix_me_
;; not entirely sure, but it must (in principle) be possible to saturate a
;; dependency from lexical and grammar rules.  say, a lexical entry selected
;; for something nominalized, and that relation was introduced by a lexical
;; rule, in turn.  unless this is the case already, compute static list of all
;; relations introduced by rules (which, presumably, requires another setting
;; to declare how to find constructional semantic contributions; C-CONT) and
;; consider all such dependencies on lexical entries always saturated.
;;                                                          (11-oct-02; oe)
unidirectional-chart-dependencies.

chart-dependencies := 
  "SYNSEM.LKEYS.--+COMPKEY" "SYNSEM.LOCAL.CAT.HEAD.MINORS.MIN"
  "SYNSEM.LKEYS.--+OCOMPKEY" "SYNSEM.LOCAL.CAT.HEAD.MINORS.MIN"
  "SYNSEM.LKEYS.--COMPHD" "SYNSEM.LOCAL.CAT.HEAD"
  "SYNSEM.LOCAL.--+ARGIND" "SYNSEM.--SIND"
.

;;
;; some rules should be constrained to only apply over the entire string, i.e.
;; to edges that span the full input; this should improve parsing efficiency
;; only, rather than be considered part of the linguistic analyses.
;;
spanning-only-rules := 
  $frag_nocop_s $frag_pp_sl $frag_vp_sl $runon_np
  $frag_l_mod_adv $frag_l_mod_vp $frag_r_mod_np 
  $frag_r_mod_i_pp $frag_r_mod_i_pp $frag_r_mod_s_pp $frag_r_mod_ap.

;;
;; as of august 2003, PET includes ECL and the generic (R)MRS code; hence, we
;; need to include the MRS settings from the grammar.
;;
postload-lisp-files := "lkb/mrsglobals.lsp".

;;
;; and as of august 2006, the MRS variable property mapping (VPM) can now be
;; activated as a configuration parameter.                    (26-aug-06; oe)
;;
vpm := "semi".

;;
;; the following two turn on (procedural) `characterization', i.e. code that
;; will destructively modify the AVMs of new edges, to record the surface
;; positions (as passed in from an external tokenizer) in each new relation.
;; i.e. those that have no characterization information yet.  this mechanism
;; is brittle (both in the LKB and PET), and we hope to eventually replace it
;; in the new chart mapping universe: there, the grammarian has full control
;; over how to `pick up' information from input tokens, and characterization
;; can be accomplished without a specialized procedure `behind the scenes'.
;;
mrs-cfrom-path := "SYNSEM.LOCAL.CONT.RELS.LIST.CFROM".
mrs-cto-path   := "SYNSEM.LOCAL.CONT.RELS.LIST.CTO".


;;;
;;; following are a number of settings for the new (as of late 2008) token
;;; mapping and lexical filtering support in PET.
;;;

;;
;; first, the general format of chart mapping rules, much like MRS transfer.
;;
chart-mapping-context-path  := "+CONTEXT".
chart-mapping-input-path    := "+INPUT".
chart-mapping-output-path   := "+OUTPUT".
chart-mapping-position-path := "+POSITION".
;;
;; in lexical instatiation, the list of tokens activating a lexical entry (be
;; it native or generic) are unified into the lexical entry under this path.
;;
lexicon-tokens-path := "TOKENS.+LIST".
lexicon-last-token-path := "TOKENS.+LAST".
;;
;; furthermore, for the various input formats, we need to declare how parts of
;; input descriptions correspond to the grammar-internal feature geometry; in
;; the YY input format, for example, token feature structures (aka input items
;; PET-internally) are created from various parts of the token description.
;; 
token-form-path     := "+FORM".       ; [required] string for lexical lookup
token-id-path       := "+ID".         ; [optional] list of external ids
token-from-path     := "+FROM".       ; [optional] surface start position
token-to-path       := "+TO".         ; [optional] surface end position
token-postags-path  := "+TNT.+TAGS".  ; [optional] list of POS tags
token-posprobs-path := "+TNT.+PRBS".  ; [optional] list of POS probabilities
;;
;; finally, declare TDL status values for the various new entity types
;;
token-mapping-rule-status-values := token-mapping-rule.
lexical-filtering-rule-status-values := lexical-filtering-rule.
generic-lexentry-status-values := generic-lex-entry.

